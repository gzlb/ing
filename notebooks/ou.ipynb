{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ornstein-Uhlenbeck Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we attempt at fitting the Ornstein-Uhlenbeck process to the given dataset. The fit is performed using Maximum Likelihood Estimation (MLE), a coarse description of this method is that given a density family, it attempts at fitting a parametrized version of a specific density. As such, it is a parametric method, highly prone to faulty assumptions. A major benefit however is the extractive nature of this method; if assumed the data correctly follows a specific process (which can be further tested using hypothesis testing), the obtained process/density will describe the data set completely, i.e. an analytical expression can be derived for the dataset. Further, assuming the data is i.i.d., the MLE method will obtain a consistent, invariant and efficient estimate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main \"routine\" for MLE can be described as follows: \n",
    "\n",
    "- Choose a distribution family, such as the Gaussian distribution, described by 2 parameters $\\theta = (\\mu, \\sigma)$, $f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp ({- \\frac{1}{2}(\\frac{x - \\mu}{\\sigma})^2 )}$\n",
    "- Given data points $x_1, \\ldots, x_n$, consider the joint density $\\mathcal{L}_n(\\theta) = \\mathcal{L}_n(\\theta, \\textbf{x}) = f_n(\\textbf{x}, \\theta) = \\prod_{i = 1}^{n} f_i(x_i, \\theta) $\n",
    "- Solve the optimization problem as $\\theta^{*} = \\argmax_{\\theta} \\mathcal{L}_n(\\theta, \\textbf{x})$ \n",
    "\n",
    "The fitted distribution is as such $\\theta^{*} = (\\mu^{*}, \\sigma^{*}) = f(x) = \\frac{1}{\\sigma^{*} \\sqrt{2\\pi}} \\exp ({- \\frac{1}{2}(\\frac{x - \\mu^{*}}{\\sigma^{*}}})^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, and likewise for the subsequent, the MLE routine is used as above. The implementation is described in more detail in the README.md, but to give a brief overview, the code can be splitted up to \n",
    "- A folder fit, which describes the statistical aspect, i.e. the density, the likelihood and maximum likelihood estimation\n",
    "- A folder models, which describes the stochastic processes such as Ornstein-Uhlenbeck and CIR\n",
    "- A folder optm, which deals with the optimization aspect of the MLE estimation, using scipy\n",
    "- A folder sim to simulate each step of the obtained process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import all necessary libraries, the work flow is fairly simple, we\n",
    "- Read the data and strip it accordingly to prepare it for the fit\n",
    "- We initialize the parameters with a guess to prepare the optimization\n",
    "- We initialize the Ornstein Uhlenbeck process \n",
    "- We initialize the MLE method to implement the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ing.models.ou import OrnsteinUhlenbeck\n",
    "from ing.fit.transition_density import ExactDensity\n",
    "from ing.fit.mle_estimator import MLE\n",
    "\n",
    "from ing.utils.data_utils import read_excel_to_series, strip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"../data/spread.xlsx\"\n",
    "COLUMN = \"Spread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20.418125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20.428125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29177</th>\n",
       "      <td>29177</td>\n",
       "      <td>22.083125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29178</th>\n",
       "      <td>29178</td>\n",
       "      <td>22.073125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29179</th>\n",
       "      <td>29179</td>\n",
       "      <td>22.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29180</th>\n",
       "      <td>29180</td>\n",
       "      <td>22.133125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181</th>\n",
       "      <td>29181</td>\n",
       "      <td>22.103125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29182 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     Spread\n",
       "0               0  20.380000\n",
       "1               1  20.400000\n",
       "2               2  20.412500\n",
       "3               3  20.418125\n",
       "4               4  20.428125\n",
       "...           ...        ...\n",
       "29177       29177  22.083125\n",
       "29178       29178  22.073125\n",
       "29179       29179  22.087500\n",
       "29180       29180  22.133125\n",
       "29181       29181  22.103125\n",
       "\n",
       "[29182 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_excel_to_series(file_path=FILE_PATH)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.38    , 20.4     , 20.4125  , ..., 22.0875  , 22.133125,\n",
       "       22.103125])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spread = strip_data(df=df, column=COLUMN)\n",
    "spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the guess and parameter boundaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds = [(0.001, 50), (0.001, 50), (0.001, 50)]\n",
    "guess = np.array([0.001, 0.001, 0.002])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the time discretization accordingly, to allocate for the 5-minute data (using the fact that there are 252 trading days, 12 5-minute intervals per hour and 8 hours in a trading day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1.0 / (252 * 12 * 8)\n",
    "model = OrnsteinUhlenbeck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the MLE is prepared, which we pipe in to all of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Params: [0.001 0.001 0.002]\n",
      "Initial Likelihood: -1897499.1568547834\n",
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 123, function evaluations: 448, CG iterations: 238, optimality: 2.35e-04, constraint violation: 0.00e+00, execution time: 0.38 s.\n",
      "Final Params: [23.21632412 21.82021766  8.07299293]\n",
      "Final Likelihood: 44653.51559948583\n"
     ]
    }
   ],
   "source": [
    "exact_est = MLE(\n",
    "    sample=spread, param_bounds=param_bounds, dt=dt, density=ExactDensity(model=model)\n",
    ").estimate_params(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.21632411912182, 21.82021765656413, 8.072992925731628)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = exact_est.params\n",
    "alpha, kappa, sigma = params[0], params[1], params[2]\n",
    "alpha, kappa, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result of the MLE, we assume the spread can be fitted as an Ornstein Uhlenbeck with parameters \n",
    "$$ dS_t = \\alpha(\\kappa - S_t)dt + \\sigma dW_t $$\n",
    "$$ dS_t = 23.22(21.82 - S_t)dt + 8.07dW_t $$ \n",
    "\n",
    "We can simulate this process using the Euler-Maruyama scheme, the most elementary discretization scheme as follows \n",
    "$$ S_{t_{n + 1}} = S_{t_{n}} + \\alpha (\\kappa - S_{t_{n}}) \\Delta t  + \\sigma \\sqrt{\\Delta t} * \\Delta W_n  $$ \n",
    "\n",
    "The discretization scheme is provided in scheme.py, with accompanying simulation in simulation.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = OrnsteinUhlenbeck()\n",
    "model_fit.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ing.models.ou.OrnsteinUhlenbeck at 0x1666d2310>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
